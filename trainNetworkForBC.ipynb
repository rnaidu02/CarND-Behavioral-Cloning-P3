{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import numpy and TF backend\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "# Import Keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Cropping2D, Lambda\n",
    "from keras import backend as K\n",
    "\n",
    "# Import cv\n",
    "import cv2\n",
    "import csv\n",
    "import sklearn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Global variables\n",
    "dataFolders = []\n",
    "homeFolder = os.getenv(\"HOME\")\n",
    "dataFolders.append(homeFolder+'/Data/')\n",
    "dataFolders.append(homeFolder+'/Desktop/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "\n",
    "# get ImageMat for the given file location in the Data log\n",
    "def process_image(folder, imageField):\n",
    "    imagePath = imageField\n",
    "    fileName = imagePath.split('/')[-1]\n",
    "    fileNamewithFolder = folder +'/IMG/' + fileName\n",
    "    imageMat = cv2.imread(fileNamewithFolder)\n",
    "    \n",
    "    return imageMat\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        sklearn.utils.shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            msm_init_count = len(angles)\n",
    "            for batch_sample in batch_samples:\n",
    "                imageMat = cv2.imread(batch_sample[0])\n",
    "                steering_center = float(batch_sample[3])\n",
    "                images.append(imageMat)\n",
    "                angles.append(steering_center)\n",
    "                # create adjusted steering measurements for the side camera images\n",
    "                correction = 0.25 # this is a parameter to tune\n",
    "                steering_left = steering_center + correction\n",
    "                steering_right = steering_center - correction\n",
    "\n",
    "                # read in images from center, left and right cameras\n",
    "                imageMat =  cv2.imread(batch_sample[1])\n",
    "                images.append(imageMat)\n",
    "                angles.append(steering_left)\n",
    "\n",
    "                imageMat =  cv2.imread(batch_sample[2])\n",
    "                images.append(imageMat)\n",
    "                angles.append(steering_right)\n",
    "            \n",
    "            # Find the existing length of images\n",
    "            list_len = len(angles)\n",
    "            for i in range(msm_init_count, list_len):\n",
    "                # Now add the image flip side to reduce the left bias\n",
    "                image_flipped = np.fliplr(images[i])\n",
    "                msmt_flipped = -1 * angles[i]\n",
    "                images.append(image_flipped)\n",
    "                angles.append(msmt_flipped)\n",
    "\n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4706\n",
      "/home/ramesh/Data/IMG/left_2017_07_12_06_34_58_813.jpg\n",
      "15042\n",
      "/home/ramesh/Data/IMG/left_2017_07_12_06_34_58_813.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    # Traverse thru the lines and extract images (X values) and steering value (y value)\\n    msm_init_count = len(msmts)\\n    for line in lines:\\n        # First element is the image\\n        imageMat = cv2.imread(line[0])\\n        images.append(imageMat)\\n        # 4th element is the steering info\\n        steering_center = float(line[3])\\n        msmts.append(steering_center)\\n\\n        # create adjusted steering measurements for the side camera images\\n        correction = 0.25 # this is a parameter to tune\\n        steering_left = steering_center + correction\\n        steering_right = steering_center - correction\\n\\n        # read in images from center, left and right cameras\\n        imageMat = cv2.imread(line[1])\\n        images.append(imageMat)\\n        msmts.append(steering_left)\\n\\n        imageMat =  cv2.imread(line[2])\\n        images.append(imageMat)\\n        msmts.append(steering_right)\\n\\n    # Find the existing length of images\\n    list_len = len(msmts)\\n    for i in range(msm_init_count, list_len):\\n\\n        # Now add the image flip side to reduce the left bias\\n        image_flipped = np.fliplr(images[i])\\n        msmt_flipped = -1 * msmts[i]\\n        images.append(image_flipped)\\n        msmts.append(msmt_flipped)\\n\\nprint(len(msmts))\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = []\n",
    "for dataFolder in dataFolders:\n",
    "\n",
    "    with open(dataFolder+'driving_log.csv') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for line in reader:\n",
    "            lines.append(line)\n",
    "        print(len(lines))\n",
    "        print (lines[0][1])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_samples, validation_samples = train_test_split(lines, test_size=0.2)\n",
    "'''\n",
    "    # Traverse thru the lines and extract images (X values) and steering value (y value)\n",
    "    msm_init_count = len(msmts)\n",
    "    for line in lines:\n",
    "        # First element is the image\n",
    "        imageMat = cv2.imread(line[0])\n",
    "        images.append(imageMat)\n",
    "        # 4th element is the steering info\n",
    "        steering_center = float(line[3])\n",
    "        msmts.append(steering_center)\n",
    "\n",
    "        # create adjusted steering measurements for the side camera images\n",
    "        correction = 0.25 # this is a parameter to tune\n",
    "        steering_left = steering_center + correction\n",
    "        steering_right = steering_center - correction\n",
    "\n",
    "        # read in images from center, left and right cameras\n",
    "        imageMat = cv2.imread(line[1])\n",
    "        images.append(imageMat)\n",
    "        msmts.append(steering_left)\n",
    "\n",
    "        imageMat =  cv2.imread(line[2])\n",
    "        images.append(imageMat)\n",
    "        msmts.append(steering_right)\n",
    "\n",
    "    # Find the existing length of images\n",
    "    list_len = len(msmts)\n",
    "    for i in range(msm_init_count, list_len):\n",
    "\n",
    "        # Now add the image flip side to reduce the left bias\n",
    "        image_flipped = np.fliplr(images[i])\n",
    "        msmt_flipped = -1 * msmts[i]\n",
    "        images.append(image_flipped)\n",
    "        msmts.append(msmt_flipped)\n",
    "\n",
    "print(len(msmts))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the traing data\n",
    "train_generator = generator(train_samples, batch_size=32)\n",
    "validation_generator = generator(validation_samples, batch_size=32)\n",
    "#print(len(train_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Build the Fully Connected Neural Network in Keras Here\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3)))\n",
    "model.add(Cropping2D(cropping=((50,20), (0,0))))\n",
    "model.add(Convolution2D(24, 5, 5,\n",
    "                activation='relu',\n",
    "                border_mode='valid'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Convolution2D(32, 5, 5,\n",
    "                activation='relu',\n",
    "                border_mode='valid'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Convolution2D(48, 5, 5,\n",
    "                activation='relu',\n",
    "                border_mode='valid'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#2nd Layer - Add a fully connected layer\n",
    "model.add(Dense(128))\n",
    "#3rd Layer - Add a ReLU activation layer\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(42))\n",
    "model.add(Dense(10))\n",
    "#4th Layer - Add a fully connected layer - one node at the end to predict steering (basically regression)\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "72198/72198 [==============================] - 123s - loss: 0.0832 - val_loss: 0.0773\n",
      "Epoch 2/3\n",
      "72198/72198 [==============================] - 111s - loss: 0.0738 - val_loss: 0.0757\n",
      "Epoch 3/3\n",
      "72198/72198 [==============================] - 114s - loss: 0.0715 - val_loss: 0.0700\n"
     ]
    }
   ],
   "source": [
    "# Times the the augmented data is generated for each line \n",
    "nAugmentedFactor = 6\n",
    "# Train the model\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "#history = model.fit(X_train, Y_train, nb_epoch=5, validation_split=0.2, shuffle=True)\n",
    "history = model.fit_generator(train_generator, samples_per_epoch= \n",
    "            nAugmentedFactor*len(train_samples), validation_data=validation_generator, \n",
    "            nb_val_samples=nAugmentedFactor*len(validation_samples), nb_epoch=6)\n",
    "\n",
    "model.save('bc_model_jul13.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
